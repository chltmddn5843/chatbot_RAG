{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24844e90",
   "metadata": {},
   "source": [
    "## ë¬¸ì„œ ì œì‘\n",
    "1. DB.ipynbì—ì„œ í†µì‹ ì‚¬ë³„ csv ì¶”ì¶œ\n",
    "2. ê²½ë¡œ ë³€ê²½ í›„ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316cdede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: python-docx in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\onedrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\rag\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1d250",
   "metadata": {},
   "source": [
    "### í†µì‹ ì‚¬ docx íŒŒì¼ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29dc097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³€í™˜ ì™„ë£Œ: C:\\Users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\OneDrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\RAGíŒŒì¼\\ìµœì¢…RAG\\í†µì‹ ì‚¬\\ì›ë³¸\\LGU+_v2.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "def format_data_limit(val, charge_pln):\n",
    "    \"\"\"ë°ì´í„° ì œê³µëŸ‰ ë‹¨ìœ„ë¥¼ MBì—ì„œ GBë¡œ ë³€í™˜í•˜ê³  ë¬´ì œí•œ ì—¬ë¶€ë¥¼ ì²´í¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if val >= 999999:\n",
    "        return \"ë¬´ì œí•œ\"\n",
    "    if pd.isna(val):\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    # MB -> GB ë³€í™˜\n",
    "    if val >= 1024:\n",
    "        gb = val / 1024\n",
    "        size_str = f\"{int(gb)}GB\" if gb == int(gb) else f\"{gb:.1f}GB\"\n",
    "    else:\n",
    "        size_str = f\"{int(val)}MB\"\n",
    "    \n",
    "    # ì†ë„ì œì–´ ë“± ì¶”ê°€ ì •ë³´ê°€ ìˆë‹¤ë©´ ê´„í˜¸ ì•ˆì— í‘œê¸°\n",
    "    if pd.notna(charge_pln) and charge_pln != \"í•´ë‹¹ì—†ìŒ\":\n",
    "        return f\"{size_str} ({charge_pln})\"\n",
    "    return size_str\n",
    "\n",
    "def format_voice(val, charge_pln):\n",
    "    \"\"\"ìŒì„± ì œê³µëŸ‰ì„ ì •ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if val >= 999999 or charge_pln == 'ë¬´ì œí•œ':\n",
    "        return \"ì œí•œì—†ìŒ\"\n",
    "    if pd.isna(val):\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    return f\"{int(val)}ë¶„\"\n",
    "\n",
    "def format_ott(nm, prd, mthd):\n",
    "    \"\"\"OTT í˜œíƒ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.\"\"\"\n",
    "    if pd.isna(nm):\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    parts = [str(nm)]\n",
    "    if pd.notna(prd): parts.append(str(prd))\n",
    "    if pd.notna(mthd): parts.append(str(mthd))\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def parse_description(desc):\n",
    "    \"\"\"AI ì„¤ëª…ì—ì„œ ì£¼ìš” íŠ¹ì§•ê³¼ ì¶”ì²œ ëŒ€ìƒì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if pd.isna(desc):\n",
    "        return \"ì •ë³´ ì—†ìŒ\", \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    lines = desc.split('\\n')\n",
    "    # ì²« ì¤„ì„ ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œ ê°„ì£¼\n",
    "    feature = lines[0].strip() if len(lines) > 0 else \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    # 'ì¶”ì²œëŒ€ìƒ:' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ ì°¾ê¸°\n",
    "    target = \"ì •ë³´ ì—†ìŒ\"\n",
    "    for line in lines:\n",
    "        if \"ì¶”ì²œëŒ€ìƒ:\" in line:\n",
    "            target = line.replace(\"ì¶”ì²œëŒ€ìƒ:\", \"\").strip()\n",
    "            break\n",
    "    \n",
    "    return feature, target\n",
    "\n",
    "def convert_csv_to_word(csv_path, output_path):\n",
    "    # 1. ë°ì´í„° ë¡œë“œ\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 2. ì›Œë“œ ë¬¸ì„œ ê°ì²´ ìƒì„±\n",
    "    doc = Document()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        name = row['PRC_PLN_NM']\n",
    "        comp = row['COMP']\n",
    "        price = f\"{row['BASE_PRICE']:,}ì›/ì›”\"\n",
    "        ott = format_ott(row['OTT_COMB_NM'], row['OTT_COMB_PRD'], row['OTT_COMB_MTHD'])\n",
    "        feature, target = parse_description(row['AI_SHORT_DESC'])\n",
    "        network = row['NW_TYPE']\n",
    "        data_prov = format_data_limit(row['DATA_PRVD'], row['DATA_CHARG_PLN'])\n",
    "        voice_prov = format_voice(row['VOICE_PRVD'], row['VOICE_CHARG_PLN'])\n",
    "        \n",
    "        # 3. ì›Œë“œì— ë‚´ìš© ì¶”ê°€\n",
    "        doc.add_paragraph(f\"# ìš”ê¸ˆì œëª… :[{comp}] {name}\")\n",
    "        doc.add_paragraph(f\"í†µì‹ ì‚¬ : {comp}\")\n",
    "        doc.add_paragraph(f\"ì´ìš©ë£Œ : {price}\")\n",
    "        doc.add_paragraph(f\"OTT í˜œíƒ : {ott}\")\n",
    "        doc.add_paragraph(f\"ì£¼ìš” íŠ¹ì§• : {feature}\")\n",
    "        doc.add_paragraph(f\"í†µì‹ ë§ : {network}\")\n",
    "        doc.add_paragraph(f\"ë°ì´í„° ì œê³µëŸ‰ : {data_prov}\")\n",
    "        doc.add_paragraph(f\"ìŒì„± ì œê³µëŸ‰ : {voice_prov}\")\n",
    "        doc.add_paragraph(f\"ì¶”ì²œ ëŒ€ìƒ : {target}\")\n",
    "        \n",
    "        # êµ¬ë¶„ì„  ì¶”ê°€ (ë§ˆì§€ë§‰ í•­ëª© ì œì™¸)\n",
    "        if index < len(df) - 1:\n",
    "            doc.add_paragraph(\"-\" * 3)\n",
    "            \n",
    "    # 4. íŒŒì¼ ì €ì¥\n",
    "    doc.save(output_path)\n",
    "    print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {output_path}\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = r'C:\\Users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\OneDrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\RAG\\data\\lgu+.csv'  # íŒŒì¼ ê²½ë¡œ\n",
    "    output_word = r'C:\\Users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\OneDrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\RAGíŒŒì¼\\ìµœì¢…RAG\\í†µì‹ ì‚¬\\ì›ë³¸\\LGU+_v2.docx'\n",
    "    convert_csv_to_word(input_csv, output_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a14cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397cf52",
   "metadata": {},
   "source": [
    "## MDíŒŒì¼ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe007ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì¤‘ë³µ êµ¬ë¶„ì ì œê±° ë° í¬ë§· ìµœì í™” ë³€í™˜ ì‹œì‘... (ì´ 116ê±´)\n",
      "âœ… ë³€í™˜ ì™„ë£Œ! ì¤‘ë³µ êµ¬ë¶„ì„ ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤: C:\\Users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\OneDrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\RAGíŒŒì¼\\ìµœì¢…RAG\\í†µì‹ ì‚¬\\md\\KT_v2.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- ì„¤ì •ë¶€ ---\n",
    "# CSV íŒŒì¼ ê²½ë¡œ\n",
    "INPUT_CSV = r'C:\\Users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\OneDrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\RAG\\data\\KT.csv' \n",
    "# ê²°ê³¼ ë§ˆí¬ë‹¤ìš´ ì €ì¥ ê²½ë¡œ\n",
    "OUTPUT_MD = r'C:\\Users\\ë¯¸ì†Œì •ë³´ê¸°ìˆ \\OneDrive - ì¸í•˜ëŒ€í•™êµ\\ë°”íƒ• í™”ë©´\\RAGíŒŒì¼\\ìµœì¢…RAG\\í†µì‹ ì‚¬\\md\\KT_v2.md'\n",
    "\n",
    "def format_data_limit(val, charge_pln):\n",
    "    if val >= 999999: return \"ë¬´ì œí•œ\"\n",
    "    if pd.isna(val): return \"ì •ë³´ ì—†ìŒ\"\n",
    "    if val >= 1024:\n",
    "        gb = val / 1024\n",
    "        size_str = f\"{int(gb)}GB\" if gb == int(gb) else f\"{gb:.1f}GB\"\n",
    "    else:\n",
    "        size_str = f\"{int(val)}MB\"\n",
    "    if pd.notna(charge_pln) and charge_pln != \"í•´ë‹¹ì—†ìŒ\":\n",
    "        return f\"{size_str} ({charge_pln})\"\n",
    "    return size_str\n",
    "\n",
    "def format_voice(val, charge_pln):\n",
    "    if val >= 999999 or charge_pln == 'ë¬´ì œí•œ': return \"ì œí•œì—†ìŒ\"\n",
    "    if pd.isna(val): return \"ì •ë³´ ì—†ìŒ\"\n",
    "    return f\"{int(val)}ë¶„\"\n",
    "\n",
    "def format_ott(nm, prd, mthd):\n",
    "    if pd.isna(nm): return \"ì •ë³´ ì—†ìŒ\"\n",
    "    parts = [str(nm)]\n",
    "    if pd.notna(prd): parts.append(str(prd))\n",
    "    if pd.notna(mthd): parts.append(str(mthd))\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def parse_description(desc):\n",
    "    if pd.isna(desc): return \"ì •ë³´ ì—†ìŒ\", \"ì •ë³´ ì—†ìŒ\"\n",
    "    lines = desc.split('\\n')\n",
    "    feature = lines[0].strip() if len(lines) > 0 else \"ì •ë³´ ì—†ìŒ\"\n",
    "    target = \"ì •ë³´ ì—†ìŒ\"\n",
    "    for line in lines:\n",
    "        if \"ì¶”ì²œëŒ€ìƒ:\" in line:\n",
    "            target = line.replace(\"ì¶”ì²œëŒ€ìƒ:\", \"\").strip()\n",
    "            break\n",
    "    return feature, target\n",
    "\n",
    "def convert_csv_to_md_v2(csv_path, output_path):\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # ê° ìš”ê¸ˆì œ(ì—”í‹°í‹°)ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸\n",
    "    entity_list = []\n",
    "\n",
    "    print(f\"ğŸš€ ì¤‘ë³µ êµ¬ë¶„ì ì œê±° ë° í¬ë§· ìµœì í™” ë³€í™˜ ì‹œì‘... (ì´ {len(df)}ê±´)\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        name = row['PRC_PLN_NM']\n",
    "        comp = row['COMP']\n",
    "        price = f\"{row['BASE_PRICE']:,}ì›/ì›”\"\n",
    "        ott = format_ott(row['OTT_COMB_NM'], row['OTT_COMB_PRD'], row['OTT_COMB_MTHD'])\n",
    "        feature, target = parse_description(row['AI_SHORT_DESC'])\n",
    "        network = row['NW_TYPE']\n",
    "        data_prov = format_data_limit(row['DATA_PRVD'], row['DATA_CHARG_PLN'])\n",
    "        voice_prov = format_voice(row['VOICE_PRVD'], row['VOICE_CHARG_PLN'])\n",
    "        \n",
    "        # 1. í•˜ë‚˜ì˜ ì—”í‹°í‹° ë¬¸ìì—´ ìƒì„± (ë³´ì—¬ì£¼ì‹  ì˜ˆì‹œì™€ ë™ì¼í•œ í˜•ì‹)\n",
    "        # í—¤ë”ë¥¼ '# ìš”ê¸ˆì œëª… : ìƒí’ˆëª…' í˜•íƒœë¡œ êµ¬ì„±\n",
    "        entity_text = (\n",
    "            f\"# ìš”ê¸ˆì œëª… :[{comp}] {name}\\n\"\n",
    "            f\"í†µì‹ ì‚¬ : {comp}\\n\"\n",
    "            f\"ì´ìš©ë£Œ : {price}\\n\"\n",
    "            f\"OTT í˜œíƒ : {ott}\\n\"\n",
    "            f\"ì£¼ìš” íŠ¹ì§• : {feature}\\n\"\n",
    "            f\"í†µì‹ ë§ : {network}\\n\"\n",
    "            f\"ë°ì´í„° ì œê³µëŸ‰ : {data_prov}\\n\"\n",
    "            f\"ìŒì„± ì œê³µëŸ‰ : {voice_prov}\\n\"\n",
    "            f\"ì¶”ì²œ ëŒ€ìƒ : {target}\"\n",
    "        )\n",
    "        entity_list.append(entity_text)\n",
    "            \n",
    "    # 2. ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¥¼ '---' êµ¬ë¶„ì í•˜ë‚˜ë¡œ ì—°ê²°\n",
    "    final_md_content = \"\\n\\n---\\n\\n\".join(entity_list)\n",
    "\n",
    "    # 3. íŒŒì¼ ì €ì¥\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_md_content)\n",
    "        \n",
    "    print(f\"âœ… ë³€í™˜ ì™„ë£Œ! ì¤‘ë³µ êµ¬ë¶„ì„ ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_csv_to_md_v2(INPUT_CSV, OUTPUT_MD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12a893",
   "metadata": {},
   "source": [
    "### ì¹´ë“œì€í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5a234",
   "metadata": {},
   "source": [
    "### êµ¬ë…ìƒí’ˆ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
